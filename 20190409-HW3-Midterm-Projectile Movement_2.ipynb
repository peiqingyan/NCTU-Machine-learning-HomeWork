{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ba30e2385650>:54: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\peiqi\\Anaconda3\\envs\\Rookie\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-ba30e2385650>:55: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From C:\\Users\\peiqi\\Anaconda3\\envs\\Rookie\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\peiqi\\Anaconda3\\envs\\Rookie\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Step 0, Loss= 139.154831, Training Accuracy= 0.464\n",
      "Step 100, Loss= 24.829165, Training Accuracy= 0.990\n",
      "Step 200, Loss= 0.002896, Training Accuracy= 1.000\n",
      "Step 300, Loss= 0.001042, Training Accuracy= 1.000\n",
      "Step 400, Loss= 0.000903, Training Accuracy= 1.000\n",
      "Step 500, Loss= 0.000765, Training Accuracy= 1.000\n",
      "Step 600, Loss= 0.000593, Training Accuracy= 1.000\n",
      "Step 700, Loss= 0.001795, Training Accuracy= 1.000\n",
      "Step 800, Loss= 0.000786, Training Accuracy= 1.000\n",
      "Step 900, Loss= 0.000479, Training Accuracy= 1.000\n",
      "Step 1000, Loss= 0.000472, Training Accuracy= 1.000\n",
      "Step 1100, Loss= 0.000358, Training Accuracy= 1.000\n",
      "Step 1200, Loss= 0.000346, Training Accuracy= 1.000\n",
      "Step 1300, Loss= 0.000925, Training Accuracy= 1.000\n",
      "Step 1400, Loss= 0.000313, Training Accuracy= 1.000\n",
      "Step 1500, Loss= 0.000365, Training Accuracy= 1.000\n",
      "Step 1600, Loss= 0.000289, Training Accuracy= 1.000\n",
      "Step 1700, Loss= 0.000285, Training Accuracy= 1.000\n",
      "Step 1800, Loss= 0.000276, Training Accuracy= 1.000\n",
      "Step 1900, Loss= 0.000257, Training Accuracy= 1.000\n",
      "Step 2000, Loss= 0.000481, Training Accuracy= 1.000\n",
      "Step 2100, Loss= 0.000253, Training Accuracy= 1.000\n",
      "Step 2200, Loss= 0.000233, Training Accuracy= 1.000\n",
      "Step 2300, Loss= 0.000246, Training Accuracy= 1.000\n",
      "Step 2400, Loss= 0.000268, Training Accuracy= 1.000\n",
      "Step 2500, Loss= 0.001088, Training Accuracy= 1.000\n",
      "Step 2600, Loss= 0.002503, Training Accuracy= 1.000\n",
      "Step 2700, Loss= 0.000190, Training Accuracy= 1.000\n",
      "Step 2800, Loss= 0.000174, Training Accuracy= 1.000\n",
      "Step 2900, Loss= 0.000169, Training Accuracy= 1.000\n",
      "Step 3000, Loss= 0.000242, Training Accuracy= 1.000\n",
      "Step 3100, Loss= 0.000150, Training Accuracy= 1.000\n",
      "Step 3200, Loss= 0.000146, Training Accuracy= 1.000\n",
      "Step 3300, Loss= 0.000189, Training Accuracy= 1.000\n",
      "Step 3400, Loss= 0.001016, Training Accuracy= 1.000\n",
      "Step 3500, Loss= 0.000388, Training Accuracy= 1.000\n",
      "Step 3600, Loss= 0.000218, Training Accuracy= 1.000\n",
      "Step 3700, Loss= 0.000129, Training Accuracy= 1.000\n",
      "Step 3800, Loss= 0.000140, Training Accuracy= 1.000\n",
      "Step 3900, Loss= 0.000184, Training Accuracy= 1.000\n",
      "Step 4000, Loss= 0.000152, Training Accuracy= 1.000\n",
      "Step 4100, Loss= 0.000113, Training Accuracy= 1.000\n",
      "Step 4200, Loss= 0.000287, Training Accuracy= 1.000\n",
      "Step 4300, Loss= 0.000112, Training Accuracy= 1.000\n",
      "Step 4400, Loss= 0.000111, Training Accuracy= 1.000\n",
      "Step 4500, Loss= 0.000169, Training Accuracy= 1.000\n",
      "Step 4600, Loss= 0.000273, Training Accuracy= 1.000\n",
      "Step 4700, Loss= 0.000116, Training Accuracy= 1.000\n",
      "Step 4800, Loss= 0.000248, Training Accuracy= 1.000\n",
      "Step 4900, Loss= 0.000122, Training Accuracy= 1.000\n",
      "Step 5000, Loss= 0.000137, Training Accuracy= 1.000\n",
      "Step 5100, Loss= 0.000338, Training Accuracy= 1.000\n",
      "Step 5200, Loss= 0.000199, Training Accuracy= 1.000\n",
      "Step 5300, Loss= 0.000096, Training Accuracy= 1.000\n",
      "Step 5400, Loss= 0.000090, Training Accuracy= 1.000\n",
      "Step 5500, Loss= 0.000741, Training Accuracy= 1.000\n",
      "Step 5600, Loss= 0.000157, Training Accuracy= 1.000\n",
      "Step 5700, Loss= 0.000122, Training Accuracy= 1.000\n",
      "Step 5800, Loss= 0.000105, Training Accuracy= 1.000\n",
      "Step 5900, Loss= 0.000187, Training Accuracy= 1.000\n",
      "Step 6000, Loss= 0.000224, Training Accuracy= 1.000\n",
      "Step 6100, Loss= 0.000223, Training Accuracy= 1.000\n",
      "Step 6200, Loss= 0.001046, Training Accuracy= 1.000\n",
      "Step 6300, Loss= 0.000085, Training Accuracy= 1.000\n",
      "Step 6400, Loss= 0.000415, Training Accuracy= 1.000\n",
      "Step 6500, Loss= 0.000188, Training Accuracy= 1.000\n",
      "Step 6600, Loss= 0.000283, Training Accuracy= 1.000\n",
      "Step 6700, Loss= 0.000182, Training Accuracy= 1.000\n",
      "Step 6800, Loss= 0.000255, Training Accuracy= 1.000\n",
      "Step 6900, Loss= 0.000122, Training Accuracy= 1.000\n",
      "Step 7000, Loss= 0.000082, Training Accuracy= 1.000\n",
      "Step 7100, Loss= 0.000101, Training Accuracy= 1.000\n",
      "Step 7200, Loss= 0.000085, Training Accuracy= 1.000\n",
      "Step 7300, Loss= 0.000122, Training Accuracy= 1.000\n",
      "Step 7400, Loss= 0.000083, Training Accuracy= 1.000\n",
      "Step 7500, Loss= 0.000905, Training Accuracy= 1.000\n",
      "Step 7600, Loss= 0.000124, Training Accuracy= 1.000\n",
      "Step 7700, Loss= 0.000243, Training Accuracy= 1.000\n",
      "Step 7800, Loss= 0.000072, Training Accuracy= 1.000\n",
      "Step 7900, Loss= 0.000131, Training Accuracy= 1.000\n",
      "Step 8000, Loss= 0.001000, Training Accuracy= 1.000\n",
      "Step 8100, Loss= 0.000213, Training Accuracy= 1.000\n",
      "Step 8200, Loss= 0.000116, Training Accuracy= 1.000\n",
      "Step 8300, Loss= 0.000081, Training Accuracy= 1.000\n",
      "Step 8400, Loss= 0.000071, Training Accuracy= 1.000\n",
      "Step 8500, Loss= 0.000077, Training Accuracy= 1.000\n",
      "Step 8600, Loss= 0.000070, Training Accuracy= 1.000\n",
      "Step 8700, Loss= 0.000242, Training Accuracy= 1.000\n",
      "Step 8800, Loss= 0.000085, Training Accuracy= 1.000\n",
      "Step 8900, Loss= 0.000071, Training Accuracy= 1.000\n",
      "Step 9000, Loss= 0.000109, Training Accuracy= 1.000\n",
      "Step 9100, Loss= 0.000124, Training Accuracy= 1.000\n",
      "Step 9200, Loss= 0.000069, Training Accuracy= 1.000\n",
      "Step 9300, Loss= 0.000098, Training Accuracy= 1.000\n",
      "Step 9400, Loss= 0.000114, Training Accuracy= 1.000\n",
      "Step 9500, Loss= 0.000063, Training Accuracy= 1.000\n",
      "Step 9600, Loss= 0.000476, Training Accuracy= 1.000\n",
      "Step 9700, Loss= 0.000079, Training Accuracy= 1.000\n",
      "Step 9800, Loss= 0.000263, Training Accuracy= 1.000\n",
      "Step 9900, Loss= 0.000064, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May 11 10:40:22 2019\n",
    "\n",
    "@author: 紅茶\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "ho=2\n",
    "g=9.8\n",
    "#Ra = (vo**2) * math.sin(deg*math.pi/180 *2) / g\n",
    "#Rb = 2 / math.tan(deg*math.pi/180)\n",
    "#R=Ra+Rb\n",
    "#H = ( vo*math.sin(deg*math.pi/180) )**2 / (2*g) + 2\n",
    "\n",
    "# 角度為45度+-10度\n",
    "# 速度為11.5+-2.5\n",
    "\n",
    "\n",
    "#data preparation\n",
    "number_pts = 10000\n",
    "deg=[]\n",
    "vo=[]\n",
    "R=[]\n",
    "H=[]\n",
    "\n",
    "for i in range(number_pts):\n",
    "    deg_tmp = 45 + np.random.normal(0.5, 3.1)\n",
    "    vo_tmp = 11.5 + np.random.normal(0.1, 0.8)\n",
    "    deg.append(deg_tmp)\n",
    "    vo.append(vo_tmp)\n",
    "    R_tmp = (vo_tmp**2)*math.sin(deg_tmp*math.pi/180*2)/g + 2/math.tan(deg_tmp*math.pi/180)\n",
    "    H_tmp = ( vo_tmp*math.sin(deg_tmp*math.pi/180) )**2 / (2*g) + 2\n",
    "    R.append(R_tmp)\n",
    "    H.append(H_tmp)\n",
    "\n",
    "\n",
    "#data package\n",
    "inputs=np.array([vo,deg],dtype=np.float32).transpose()\n",
    "outcome=np.array([R,H],dtype=np.float32).transpose()\n",
    "\n",
    "with tf.variable_scope('inputs',reuse=tf.AUTO_REUSE):\n",
    "    tf_inputs=tf.placeholder(tf.float32,[None,2],name='inputs')\n",
    "with tf.variable_scope('outcome',reuse=tf.AUTO_REUSE):\n",
    "    tf_outcome=tf.placeholder(tf.float32,[None,2],name='outcome')\n",
    "\n",
    "\n",
    "#NN\n",
    "with tf.variable_scope('Net',reuse=tf.AUTO_REUSE):\n",
    "    L1=tf.layers.dense(tf_inputs,16,tf.nn.relu,name='hidden_layer1')\n",
    "    L1_BN=tf.layers.batch_normalization(inputs=L1,training=True,name='batch_normalization_layer1')\n",
    "\n",
    "    L2=tf.layers.dense(L1_BN,64,tf.nn.relu,name='hidden_layer2')\n",
    "    L2_BN=tf.layers.batch_normalization(inputs=L2,training=True,name='batch_normalization_layer2')\n",
    "\n",
    "    L3=tf.layers.dense(L2_BN,16,tf.nn.relu,name='hidden_layer3')\n",
    "    L3_BN=tf.layers.batch_normalization(inputs=L3,training=True,name='batch_normalization_layer3')\n",
    "\n",
    "    output=tf.layers.dense(L3_BN,2)\n",
    "\n",
    "\n",
    "\n",
    "#construct model\n",
    "logits=output\n",
    "prediction=tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "#loss function,optimizer,initialization,accuracy\n",
    "loss_op=tf.losses.mean_squared_error(tf_outcome,output,scope='loss')\n",
    "\n",
    "with tf.variable_scope('train_op',reuse=tf.AUTO_REUSE):\n",
    "    train_op=tf.train.AdamOptimizer(0.005).minimize(loss_op)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#evaluate model\n",
    "correct_pred=tf.equal(tf.argmax(prediction,1),tf.argmax(tf_outcome,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "#session run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(10000):\n",
    "        _,L,predic=sess.run([train_op,loss_op,output],feed_dict={tf_inputs:inputs,tf_outcome:outcome})\n",
    "        if step%100==0:\n",
    "            loss,acc=sess.run([loss_op,accuracy],feed_dict={tf_inputs:inputs,tf_outcome:outcome})\n",
    "            \n",
    "            print(\"Step \" + str(step) + \", Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    print('Optimization Finished!')\n",
    "            \n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={tf_inputs:inputs,tf_outcome:outcome}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
